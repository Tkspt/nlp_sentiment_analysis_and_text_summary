{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional, GRU, Dropout\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               text\n",
      "0      0  - Awww, c'est un bummer. Tu devrais avoir davi...\n",
      "1      0  Est contrarié qu'il ne puisse pas mettre à jou...\n",
      "2      0  J'ai plongé plusieurs fois pour la balle. A ré...\n",
      "3      0  Tout mon corps a des démangeaisons et comme si...\n",
      "4      0  Non, il ne se comporte pas du tout. je suis en...\n"
     ]
    }
   ],
   "source": [
    "# Importer les données\n",
    "path = './data/french_tweets.csv'\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Afficher les données\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diminuons la taille du df\n",
    "df = df.loc[:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6001, 2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Awww, c'est un bummer. Tu devrais avoir david carr du troisième jour pour le faire. ;ré\n"
     ]
    }
   ],
   "source": [
    "print(df['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nettoyage du df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.73)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-md==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-3.7.0/fr_core_news_md-3.7.0-py3-none-any.whl (45.8 MB)\n",
      "     ---------------------------------------- 45.8/45.8 MB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fr-core-news-md==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.28.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.24.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\morcodou.seck\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\morcodou.seck\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-md==3.7.0) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_md')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Installation de spacy et téléchargement de fr_core_news_md\n",
    "!python -m spacy download fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "import spacy\n",
    "\n",
    "nlp_spacy = spacy.load('fr_core_news_md')\n",
    "Stopwords = stopwords.words('french')\n",
    "\n",
    "def cleannig_tweet(text):\n",
    "    expanded_all = []\n",
    "    text = re.sub(r'http[s]*:?//\\S+','', text)\n",
    "    text = re.sub(r'@[\\w\\-\\.]+', '', text)\n",
    "    text = re.sub(r'[\\w\\-\\.]+@[\\w\\-\\.]+', '', text)\n",
    "    text = re.sub(r'&\\w+','', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]+', ' ', text)\n",
    "    text = re.sub(r'^\\s|\\s$', '', text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text).lower()\n",
    "    \n",
    "    \n",
    "    for word in text.split():\n",
    "        expanded_all.append(contractions.fix(word))\n",
    "    text = ' '.join(expanded_all)\n",
    "    \n",
    "    \n",
    "    text = ' '.join([word for word in text.split() if word not in Stopwords])\n",
    "\n",
    "    tokens  = nlp_spacy(text)\n",
    "    text = [word.lemma_ for word in tokens]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer la fonction cleannig_tweet\n",
    "df['tweet'] = df.text.apply(func = cleannig_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Awww, c'est un bummer. Tu devrais avoir david carr du troisième jour pour le faire. ;ré\n",
      "awww bummer devoir avoir david carr troisi jour faire r\n"
     ]
    }
   ],
   "source": [
    "print(df['text'][0])\n",
    "print(df['tweet'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>- Awww, c'est un bummer. Tu devrais avoir davi...</td>\n",
       "      <td>awww bummer devoir avoir david carr troisi jou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Est contrarié qu'il ne puisse pas mettre à jou...</td>\n",
       "      <td>contrari pouvoir mettre jour facebook maignant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>J'ai plongé plusieurs fois pour la balle. A ré...</td>\n",
       "      <td>plong plusieurs fois balle avoir r ussi conomi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Tout mon corps a des démangeaisons et comme si...</td>\n",
       "      <td>tout corps avoir mangeaison comme si taire feu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Non, il ne se comporte pas du tout. je suis en...</td>\n",
       "      <td>non comporte tout col r pourquoi ici parce pou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      0  - Awww, c'est un bummer. Tu devrais avoir davi...   \n",
       "1      0  Est contrarié qu'il ne puisse pas mettre à jou...   \n",
       "2      0  J'ai plongé plusieurs fois pour la balle. A ré...   \n",
       "3      0  Tout mon corps a des démangeaisons et comme si...   \n",
       "4      0  Non, il ne se comporte pas du tout. je suis en...   \n",
       "\n",
       "                                               tweet  \n",
       "0  awww bummer devoir avoir david carr troisi jou...  \n",
       "1  contrari pouvoir mettre jour facebook maignant...  \n",
       "2  plong plusieurs fois balle avoir r ussi conomi...  \n",
       "3     tout corps avoir mangeaison comme si taire feu  \n",
       "4  non comporte tout col r pourquoi ici parce pou...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichons le jeu de données\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vectorisation des tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorison avec Tokenizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Nombre de mots\n",
    "nbr_word_unique = len(set(\" \".join(df.tweet).split()))\n",
    "\n",
    "# Initialiser le modèle Tokenizer\n",
    "tokenizer = Tokenizer(num_words = nbr_word_unique, split=' ')\n",
    "\n",
    "# Entrainer les données\n",
    "tokenizer.fit_on_texts(df['tweet'].values)\n",
    "\n",
    "# Vectoriser\n",
    "vect_array = tokenizer.texts_to_sequences(df['tweet'].values)\n",
    "\n",
    "# Padding\n",
    "vect_array = pad_sequences(vect_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le tokenizer en JSON\n",
    "tokenizer_json = tokenizer.to_json()\n",
    "with open('french_tokenizer.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(tokenizer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7682"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Le nombre de mot uniques dans les tweets\n",
    "nbr_word_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définission des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Installons keras-tuner\n",
    "!pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Séparation des données en train, test et validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Labels\n",
    "y = df.label.values\n",
    "\n",
    "# Splitter en train et test\n",
    "x_train, x_test, y_train, y_test = train_test_split(vect_array, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Splitter validation et test\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définissons l'opitmizer\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidir_lstm_model_builder(hp):\n",
    "    emb_dimention = hp.Int('emb_dimention', min_value=32, max_value=512, step=32)\n",
    "    nbr_neurones = hp.Int('nbr_neurones', min_value=32, max_value=512, step=32)\n",
    "    nbr_neurones_l2 = hp.Int('nbr_neurones', min_value=32, max_value=512, step=32)\n",
    "    learning_rate = hp.Choice('learning_rate', values=[0.01, 0.001, 0.0001])\n",
    "    dropout = hp.Boolean(\"dropout\")\n",
    "    \n",
    "    Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    bidir_lstm_model=Sequential()\n",
    "    bidir_lstm_model.add(Embedding(nbr_word_unique, emb_dimention, input_length=vect_array.shape[1]))\n",
    "    bidir_lstm_model.add(Bidirectional(LSTM(nbr_neurones, return_sequences=True)))\n",
    "    if dropout :\n",
    "        bidir_lstm_model.add(Dropout(0.4))\n",
    "    bidir_lstm_model.add(Bidirectional(LSTM(nbr_neurones_l2)))\n",
    "    if dropout: \n",
    "        bidir_lstm_model.add(Dropout(0.4))\n",
    "    bidir_lstm_model.add(Dense(1,activation='sigmoid'))\n",
    "    bidir_lstm_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    return bidir_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidir_gru_model_builder(hp):\n",
    "    emb_dimention = hp.Int('emb_dimention', min_value=32, max_value=512, step=32)\n",
    "    nbr_neurones = hp.Int('nbr_neurones', min_value=32, max_value=512, step=32)\n",
    "    nbr_neurones_l2 = hp.Int('nbr_neurones', min_value=32, max_value=512, step=32)\n",
    "    learning_rate = hp.Choice('learning_rate', values=[0.01, 0.001, 0.0001])\n",
    "    dropout = hp.Boolean(\"dropout\")\n",
    "    \n",
    "    Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    bidir_gru_model=Sequential()\n",
    "    bidir_gru_model.add(Embedding(nbr_word_unique, emb_dimention, input_length=vect_array.shape[1]))\n",
    "    bidir_gru_model.add(Bidirectional(GRU(nbr_neurones, return_sequences=True)))\n",
    "    if dropout :\n",
    "        bidir_gru_model.add(Dropout(0.4))\n",
    "    bidir_gru_model.add(Bidirectional(GRU(nbr_neurones_l2)))\n",
    "    if dropout: \n",
    "        bidir_gru_model.add(Dropout(0.4))\n",
    "    bidir_gru_model.add(Dense(1,activation='sigmoid'))\n",
    "    bidir_gru_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    return bidir_gru_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model_builder(hp):\n",
    "    emb_dimention = hp.Int('emb_dimention', min_value=32, max_value=512, step=32)\n",
    "    nbr_neurones = hp.Int('nbr_neurones', min_value=32, max_value=512, step=32)\n",
    "    nbr_neurones_l2 = hp.Int('nbr_neurones', min_value=32, max_value=512, step=32)\n",
    "    learning_rate = hp.Choice('learning_rate', values=[0.01, 0.001, 0.0001])\n",
    "    dropout = hp.Boolean(\"dropout\")\n",
    "    \n",
    "    Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    lstm_model=Sequential()\n",
    "    lstm_model.add(Embedding(nbr_word_unique, emb_dimention, input_length=vect_array.shape[1]))\n",
    "    lstm_model.add(LSTM(nbr_neurones, return_sequences=True))\n",
    "    if dropout :\n",
    "        lstm_model.add(Dropout(0.4))\n",
    "    lstm_model.add(LSTM(nbr_neurones_l2))\n",
    "    if dropout: \n",
    "        lstm_model.add(Dropout(0.4))\n",
    "    lstm_model.add(Dense(1,activation='sigmoid'))\n",
    "    lstm_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_model_builder(hp):\n",
    "    emb_dimention = hp.Int('emb_dimention', min_value=32, max_value=512, step=32)\n",
    "    nbr_neurones = hp.Int('nbr_neurones', min_value=32, max_value=512, step=32)\n",
    "    nbr_neurones_l2 = hp.Int('nbr_neurones', min_value=32, max_value=512, step=32)\n",
    "    learning_rate = hp.Choice('learning_rate', values=[0.01, 0.001, 0.0001])\n",
    "    dropout = hp.Boolean(\"dropout\")\n",
    "    \n",
    "    Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    gru_model=Sequential()\n",
    "    gru_model.add(Embedding(nbr_word_unique, emb_dimention, input_length=vect_array.shape[1]))\n",
    "    gru_model.add(GRU(nbr_neurones, return_sequences=True))\n",
    "    if dropout :\n",
    "        gru_model.add(Dropout(0.4))\n",
    "    gru_model.add(GRU(nbr_neurones_l2))\n",
    "    if dropout: \n",
    "        gru_model.add(Dropout(0.4))\n",
    "    gru_model.add(Dense(1,activation='sigmoid'))\n",
    "    gru_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    return gru_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(model_to_tune):\n",
    "    # Mettons en place un rapel d'arrêt après avoir atteint une certaine valeur\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "    \n",
    "    # Instancions le tuner\n",
    "    tuner = kt.RandomSearch(\n",
    "        model_to_tune,\n",
    "        objective='val_accuracy',\n",
    "        max_trials = 2,\n",
    "        overwrite = True,\n",
    "        directory='tuners_dir',\n",
    "        project_name='intro_to_kt'\n",
    "    )\n",
    "    \n",
    "    # Exécutons la recherche des paramètres\n",
    "    tuner.search(x_train, y_train, validation_data=(x_val, y_val), epochs=3, callbacks=[stop_early])\n",
    "    \n",
    "    return tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 45s]\n",
      "val_accuracy: 1.0\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 05m 13s\n"
     ]
    }
   ],
   "source": [
    "# Récupérons les models tunes\n",
    "print(\"bi dir lstm\")\n",
    "bidir_lstm_tuner = tune_model(bidir_lstm_model_builder)\n",
    "\n",
    "print(\"\\nbi dir gru\")\n",
    "bidir_gru_tuner = tune_model(bidir_gru_model_builder)\n",
    "\n",
    "print(\"\\nlstm\")\n",
    "lstm_tuner = tune_model(lstm_model_builder)\n",
    "\n",
    "print(\"\\n gru\")\n",
    "gru_tuner = tune_model(gru_model_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construisons les modèles\n",
    "bidir_lstm_model = bidir_lstm_tuner.hypermodel.build(bidir_lstm_tuner.get_best_hyperparameters(num_trials=1)[0])\n",
    "bidir_gru_model = bidir_gru_tuner.hypermodel.build(bidir_gru_tuner.get_best_hyperparameters(num_trials=1)[0])\n",
    "lstm_model = lstm_tuner.hypermodel.build(lstm_tuner.get_best_hyperparameters(num_trials=1)[0])\n",
    "gru_model = gru_tuner.hypermodel.build(gru_tuner.get_best_hyperparameters(num_trials=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    {\"name\": \"bidirectional LSTM\", \"model\": bidir_lstm_model, \"score\": 0},\n",
    "    {\"name\": \"LSTM\", \"model\": lstm_model, \"score\": 0},\n",
    "    {\"name\": \"bidirectional GRU\", \"model\": bidir_gru_model, \"score\": 0},\n",
    "    {\"name\": \"GRU\", \"model\": gru_model, \"score\": 0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bidirectional LSTM\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 25, 448)           3441536   \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 25, 640)           1968640   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 25, 640)           0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 640)               2460160   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 640)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 641       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7870977 (30.03 MB)\n",
      "Trainable params: 7870977 (30.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "LSTM\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 25, 96)            737472    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 25, 224)           287616    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 25, 224)           0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 224)               402304    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 224)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 225       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1427617 (5.45 MB)\n",
      "Trainable params: 1427617 (5.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "bidirectional GRU\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 25, 160)           1229120   \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirecti  (None, 25, 512)           642048    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirecti  (None, 512)               1182720   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3054401 (11.65 MB)\n",
      "Trainable params: 3054401 (11.65 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "GRU\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 25, 448)           3441536   \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 25, 448)           1206912   \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 448)               1206912   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 449       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5855809 (22.34 MB)\n",
      "Trainable params: 5855809 (22.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model[\"name\"])\n",
    "    print(model[\"model\"].summary())\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement et Validation des modèles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entrainement et validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle bidirectional LSTM\n",
      "Epoch 1/5\n",
      "75/75 [==============================] - 103s 1s/step - loss: 0.0160 - accuracy: 0.9985 - val_loss: 3.0411e-11 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "75/75 [==============================] - 92s 1s/step - loss: 6.0761e-11 - accuracy: 1.0000 - val_loss: 3.0217e-11 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "75/75 [==============================] - 91s 1s/step - loss: 5.9500e-11 - accuracy: 1.0000 - val_loss: 3.0215e-11 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "75/75 [==============================] - 91s 1s/step - loss: 6.3659e-11 - accuracy: 1.0000 - val_loss: 3.0212e-11 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "75/75 [==============================] - 95s 1s/step - loss: 6.1604e-11 - accuracy: 1.0000 - val_loss: 3.0209e-11 - val_accuracy: 1.0000\n",
      "19/19 [==============================] - 7s 269ms/step\n",
      "Modèle LSTM\n",
      "Epoch 1/5\n",
      "75/75 [==============================] - 18s 192ms/step - loss: 0.0321 - accuracy: 0.9971 - val_loss: 1.2461e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "75/75 [==============================] - 14s 189ms/step - loss: 2.4830e-07 - accuracy: 1.0000 - val_loss: 1.1659e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "75/75 [==============================] - 14s 190ms/step - loss: 2.3115e-07 - accuracy: 1.0000 - val_loss: 1.0922e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "75/75 [==============================] - 14s 182ms/step - loss: 2.2110e-07 - accuracy: 1.0000 - val_loss: 1.0196e-07 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "75/75 [==============================] - 14s 184ms/step - loss: 1.9939e-07 - accuracy: 1.0000 - val_loss: 9.5417e-08 - val_accuracy: 1.0000\n",
      "19/19 [==============================] - 2s 49ms/step\n",
      "Modèle bidirectional GRU\n",
      "Epoch 1/5\n",
      "75/75 [==============================] - 72s 859ms/step - loss: 0.0266 - accuracy: 0.9996 - val_loss: 1.4036e-13 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "75/75 [==============================] - 63s 841ms/step - loss: 1.3959e-13 - accuracy: 1.0000 - val_loss: 1.4031e-13 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "75/75 [==============================] - 63s 832ms/step - loss: 1.3958e-13 - accuracy: 1.0000 - val_loss: 1.4031e-13 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "75/75 [==============================] - 62s 827ms/step - loss: 1.3958e-13 - accuracy: 1.0000 - val_loss: 1.4031e-13 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "75/75 [==============================] - 62s 824ms/step - loss: 1.3958e-13 - accuracy: 1.0000 - val_loss: 1.4031e-13 - val_accuracy: 1.0000\n",
      "19/19 [==============================] - 4s 153ms/step\n",
      "Modèle GRU\n",
      "Epoch 1/5\n",
      "75/75 [==============================] - 58s 724ms/step - loss: 0.0264 - accuracy: 0.9917 - val_loss: 4.8222e-10 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "75/75 [==============================] - 54s 723ms/step - loss: 4.8394e-10 - accuracy: 1.0000 - val_loss: 4.8426e-10 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "75/75 [==============================] - 53s 713ms/step - loss: 4.8369e-10 - accuracy: 1.0000 - val_loss: 4.8358e-10 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "75/75 [==============================] - 55s 738ms/step - loss: 4.8294e-10 - accuracy: 1.0000 - val_loss: 4.8277e-10 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "75/75 [==============================] - 54s 717ms/step - loss: 4.8208e-10 - accuracy: 1.0000 - val_loss: 4.8185e-10 - val_accuracy: 1.0000\n",
      "19/19 [==============================] - 4s 183ms/step\n"
     ]
    }
   ],
   "source": [
    "# entrainement et validation des modèles\n",
    "for model in models:\n",
    "    print(f\"Modèle {model['name']}\")\n",
    "    model['model'].fit(x_train, y_train, validation_data=(x_val, y_val), epochs=5, batch_size=64)\n",
    "    \n",
    "    # Prédire les labels de x_val\n",
    "    y_pred = model['model'].predict(x_val)\n",
    "    \n",
    "    # Arrondir les valeurs\n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    # calculons l'accuracy\n",
    "    model['score'] = accuracy_score(y_pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bidirectional LSTM: 1.0\n",
      "LSTM: 1.0\n",
      "bidirectional GRU: 1.0\n",
      "GRU: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Affichons les scores et choisissons le meilleur modèle\n",
    "choosed_model = models[0]\n",
    "for model in models:\n",
    "    print(f\"{model['name']}: {model['score']}\")\n",
    "    if(model['score'] > choosed_model['score']):\n",
    "        choosed_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle choisi est :\n",
      "bidirectional LSTM: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Affichons le modèle choisi\n",
    "print(\"Le modèle choisi est :\")\n",
    "print(f\"{choosed_model['name']}: {choosed_model['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\morcodou.seck\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# sauvegarde du modèle\n",
    "choosed_model['model'].save(\"models/french_sentiment_analysis.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
